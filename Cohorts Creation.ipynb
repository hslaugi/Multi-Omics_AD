{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "024187e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e435e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_clinical = 'ADNIMERGE/ADNIMERGE_08Jan2026.csv'\n",
    "file_proteomics = 'RBM/adni_proteomicsv2/adni_plasma_qc_multiplex_11Nov2010.csv'\n",
    "file_expression = 'ADNI_Gene_Expression_Profile/ADNI_Gene_Expression_Profile.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b272c281",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"Processed_Data\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99edb3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Clinical Data (ADNIMERGE)...\n",
      "Baseline Clinical Subjects: 2430\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Clinical Data (ADNIMERGE)...\")\n",
    "df_clin = pd.read_csv(file_clinical, low_memory=False)\n",
    "\n",
    "# FILTER: Keeping only Baseline ('bl') visits\n",
    "# We anchor to baseline to match the timing of the omics samples.\n",
    "df_clin_bl = df_clin[df_clin['VISCODE'] == 'bl'].copy()\n",
    "\n",
    "# CLEANUP: Selecting essential columns\n",
    "# We keep Diagnosis (DX_bl), Scores (MMSE, CDRSB), and Demographics\n",
    "cols_to_keep = ['RID', 'PTID', 'VISCODE', 'EXAMDATE', 'AGE', 'PTGENDER', \n",
    "                'PTEDUCAT', 'PTETHCAT', 'PTRACCAT', 'APOE4', 'DX_bl', \n",
    "                'MMSE', 'CDRSB', 'ADAS13']\n",
    "\n",
    "# Robust selection: only keep columns that actually exist in the file\n",
    "actual_cols = [c for c in cols_to_keep if c in df_clin_bl.columns]\n",
    "df_clin_clean = df_clin_bl[actual_cols].copy()\n",
    "\n",
    "# Fix RIDs: Ensure they are integers for merging\n",
    "df_clin_clean['RID'] = pd.to_numeric(df_clin_clean['RID'], errors='coerce')\n",
    "df_clin_clean = df_clin_clean.dropna(subset=['RID'])\n",
    "df_clin_clean['RID'] = df_clin_clean['RID'].astype(int)\n",
    "\n",
    "print(f\"Baseline Clinical Subjects: {len(df_clin_clean)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3983ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Raw Proteomics (RBM Plasma)...\n",
      "Total Subjects with Proteomics: 566\n"
     ]
    }
   ],
   "source": [
    "# PREPARE PROTEOMICS (TIER 1)\n",
    "\n",
    "print(\"Loading Raw Proteomics (RBM Plasma)...\")\n",
    "df_prot = pd.read_csv(file_proteomics)\n",
    "\n",
    "# CLEANUP: \n",
    "# 1. Ensure RID is integer\n",
    "df_prot['RID'] = pd.to_numeric(df_prot['RID'], errors='coerce')\n",
    "df_prot = df_prot.dropna(subset=['RID'])\n",
    "df_prot['RID'] = df_prot['RID'].astype(int)\n",
    "\n",
    "# 2. Remove duplicates (Keep first instance per RID)\n",
    "# Some patients might have duplicate entries; we take the first valid one.\n",
    "df_prot_clean = df_prot.drop_duplicates(subset=['RID'])\n",
    "\n",
    "print(f\"Total Subjects with Proteomics: {len(df_prot_clean)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d37d8f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Raw Gene Expression ...\n",
      "Total Subjects with Transcriptomics: 744\n"
     ]
    }
   ],
   "source": [
    "# PREPARE GENOMICS (TIER 2)\n",
    "print(\"Loading Raw Gene Expression ...\")\n",
    "# This file is complex because it is transposed (Genes = Rows).\n",
    "# We read it without a header first to locate the data.\n",
    "df_gene_raw = pd.read_csv(file_expression, header=None, low_memory=False)\n",
    "\n",
    "# Logic to find the row containing Subject IDs (like '011_S_1234')\n",
    "id_row_idx = -1\n",
    "for i in range(10): # Scan first 10 rows\n",
    "    row_str = df_gene_raw.iloc[i].astype(str)\n",
    "    # Check if row has multiple IDs containing '_S_'\n",
    "    if row_str.str.contains('_S_').sum() > 5:\n",
    "        id_row_idx = i\n",
    "        break\n",
    "\n",
    "if id_row_idx != -1:\n",
    "    # Extract Data\n",
    "    subject_ids = df_gene_raw.iloc[id_row_idx, 2:].values # Skip probe cols\n",
    "    gene_data = df_gene_raw.iloc[id_row_idx+1:, 2:].values\n",
    "    gene_names = df_gene_raw.iloc[id_row_idx+1:, 1].values # Gene Symbols\n",
    "    \n",
    "    # Transpose: Create DataFrame where Rows = Subjects, Cols = Genes\n",
    "    df_gene_clean = pd.DataFrame(gene_data.T, columns=gene_names)\n",
    "    df_gene_clean.insert(0, 'PTID', subject_ids)\n",
    "    \n",
    "    # Extract RID from PTID ('011_S_1234' -> 1234) for merging\n",
    "    df_gene_clean['RID'] = df_gene_clean['PTID'].apply(lambda x: int(x.split('_')[-1]) if '_S_' in str(x) else np.nan)\n",
    "    df_gene_clean.dropna(subset=['RID'], inplace=True)\n",
    "    df_gene_clean['RID'] = df_gene_clean['RID'].astype(int)\n",
    "    \n",
    "    # Handle duplicate RIDs in gene file if any\n",
    "    df_gene_clean = df_gene_clean.drop_duplicates(subset=['RID'])\n",
    "    \n",
    "    print(f\"Total Subjects with Transcriptomics: {len(df_gene_clean)}\")\n",
    "else:\n",
    "    print(\"   ! ERROR: Could not parse Gene file headers. Check file format.\")\n",
    "    df_gene_clean = pd.DataFrame(columns=['RID']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "024cf00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Tiered Cohorts...\n",
      "TIER 1 (Proteomics + Clinical): 566 Subjects\n",
      "TIER 2 (Multi-Omics + Clinical): 170 Subjects\n"
     ]
    }
   ],
   "source": [
    "# MERGE AND EXPORT COHORTS\n",
    "print(\"Generating Tiered Cohorts...\")\n",
    "\n",
    "# TIER 1: PROTEOMIC COHORT (Aim 1 Training)\n",
    "# Merge Clinical + Proteomics\n",
    "# How='inner' keeps only intersection\n",
    "tier1_df = pd.merge(df_clin_clean, df_prot_clean, on='RID', how='inner', suffixes=('', '_prot'))\n",
    "\n",
    "# TIER 2: MULTI-OMICS COHORT (Aim 1 Refinement & Aim 2 Fusion)\n",
    "# Merge Tier 1 + Genomics\n",
    "tier2_df = pd.merge(tier1_df, df_gene_clean, on='RID', how='inner', suffixes=('', '_gene'))\n",
    "\n",
    "# SAVE RESULTS\n",
    "\n",
    "print(f\"TIER 1 (Proteomics + Clinical): {len(tier1_df)} Subjects\")\n",
    "print(f\"TIER 2 (Multi-Omics + Clinical): {len(tier2_df)} Subjects\")\n",
    "\n",
    "# Export to CSV\n",
    "tier1_path = os.path.join(output_dir, 'Tier1_Proteomics_Cohort.csv')\n",
    "tier2_path = os.path.join(output_dir, 'Tier2_MultiOmics_Cohort.csv')\n",
    "\n",
    "tier1_df.to_csv(tier1_path, index=False)\n",
    "tier2_df.to_csv(tier2_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae61f7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
